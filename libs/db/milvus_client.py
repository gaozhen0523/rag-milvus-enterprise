#libs/db/milvus_client.py
import os
from dotenv import load_dotenv
from typing import List, Optional
from pymilvus import (
    connections,
    FieldSchema,
    CollectionSchema,
    DataType,
    Collection,
    utility,
)
import numpy as np

load_dotenv(override=False)


class MilvusClientFactory:
    """
    Milvusè¿æ¥å·¥å‚ï¼š
    - ä»ç¯å¢ƒå˜é‡è¯»å– MILVUS_HOST / MILVUS_PORT
    - è‡ªåŠ¨å»ºç«‹æˆ–å¤ç”¨è¿æ¥
    - æä¾› collection åˆå§‹åŒ– / ç´¢å¼• / åŠ è½½å·¥å…·
    """

    def __init__(self, host=None, port=None, collection_name=None):
        self.host = host or os.getenv("MILVUS_HOST", "127.0.0.1")
        self.port = port or os.getenv("MILVUS_PORT", "19530")
        self.collection_name = collection_name or os.getenv("MILVUS_COLLECTION", "rag_collection")

    # -------------------------------
    # è¿æ¥ç®¡ç†
    # -------------------------------
    def connect(self, alias: str = "default"):
        """è¿æ¥Milvusï¼Œå¦‚æœè¿æ¥å·²å­˜åœ¨åˆ™å¤ç”¨"""
        if connections.has_connection(alias):
            print(f"ğŸ” Reusing existing Milvus connection ({alias})")
            return True
        connections.connect(alias=alias, host=self.host, port=self.port)
        print(f"âœ… Connected to Milvus at {self.host}:{self.port}")
        return True

    # -------------------------------
    # Collection åˆå§‹åŒ–
    # -------------------------------
    def get_or_create_collection(self, name=None, dim=768, alias="default"):
        name = name or self.collection_name
        """è·å–æˆ–åˆ›å»º collection"""
        self.connect(alias)

        if utility.has_collection(name, using=alias):
            print(f"â„¹ï¸ Collection '{name}' already exists.")
            return Collection(name=name, using=alias)

        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=dim),
            FieldSchema(name="doc_id", dtype=DataType.VARCHAR, max_length=128),
            FieldSchema(name="chunk_id", dtype=DataType.INT64),
            FieldSchema(name="meta", dtype=DataType.JSON),
        ]
        schema = CollectionSchema(fields, description="RAG document chunks")
        collection = Collection(name=name, schema=schema, using=alias)
        print(f"âœ… Created new collection: {name}")
        return collection

    # -------------------------------
    # ç´¢å¼• + åŠ è½½
    # -------------------------------
    def ensure_index_and_load(
        self,
        collection: Collection,
        index_type="IVF_FLAT",
        metric_type="L2",
        nlist=128,
    ):
        """åˆ›å»ºç´¢å¼•å¹¶åŠ è½½åˆ°å†…å­˜"""
        index_params = {
            "metric_type": metric_type,
            "index_type": index_type,
            "params": {"nlist": nlist},
        }
        # å¦‚æœå·²å­˜åœ¨ç´¢å¼•åˆ™è·³è¿‡
        try:
            current_indexes = collection.indexes
            if current_indexes and len(current_indexes) > 0:
                print(f"â„¹ï¸ Index already exists on '{collection.name}', skip create_index.")
            else:
                collection.create_index(field_name="vector", index_params=index_params)
        except Exception as e:
            # æŸäº›ç‰ˆæœ¬/åœºæ™¯ collection.indexes å¯èƒ½ä¸å¯ç”¨ï¼Œå…œåº•åˆ›å»º
            try:
                collection.create_index(field_name="vector", index_params=index_params)
            except Exception as inner:
                print(f"âš ï¸ create_index skipped or failed: {inner}")

        collection.load()
        print(f"âœ… Index ensured and collection loaded: {collection.name}")
        return index_params

    # -------------------------------
    # Demo æ•°æ®æ’å…¥ï¼ˆç”¨äºåˆå§‹åŒ–éªŒè¯ï¼‰
    # -------------------------------
    def insert_demo_data(self, collection: Collection, num_rows: int = 5, dim: int = 768):
        """æ’å…¥ä¸€äº›éšæœºå‘é‡è¿›è¡ŒéªŒè¯"""
        import numpy as np
        vectors = np.random.random((num_rows, dim)).astype("float32").tolist()
        doc_ids = [f"doc_{i}" for i in range(num_rows)]
        chunk_ids = list(range(num_rows))
        metas = [{"source": "demo", "tags": ["init", "day3"]} for _ in range(num_rows)]

        # åˆ—æ¨¡å¼æ’å…¥ï¼Œé¡ºåºå¿…é¡»ä¸ schema ä¸­å®šä¹‰ä¸€è‡´ï¼ˆé™¤ä¸»é”®ï¼‰
        data = [vectors, doc_ids, chunk_ids, metas]

        result = collection.insert(data)
        collection.flush()

        print(f"âœ… Inserted {len(result.primary_keys)} demo rows into '{collection.name}'")
        print(f"Total entities now: {collection.num_entities}")
        return result

    # -------------------------------
    # å¥åº·æ£€æŸ¥
    # -------------------------------
    def health_status(self):
        """è¿”å› Milvus è¿æ¥ä¸ Collection çŠ¶æ€"""
        try:
            self.connect()
            version = utility.get_server_version()
            has_col = utility.has_collection(self.collection_name)
            return {
                "status": "ok",
                "version": version,
                "rag_collection": has_col,
                "collection": self.collection_name,
                "host": self.host,
                "port": self.port,
            }
        except Exception as e:
            return {"status": "error", "detail": str(e)}

    def search_vectors(
            self,
            query_vector: np.ndarray,
            top_k: int = 5,
            collection_name: Optional[str] = None,
            metric_type: str = "L2",
            nprobe: int = 8,
            output_fields: Optional[List[str]] = None,
            alias: str = "default",
    ):
        """
        åœ¨æŒ‡å®š collection ä¸Šæ‰§è¡Œå‘é‡æ£€ç´¢ã€‚
        è¿”å›ï¼šList[ {doc_id, chunk_id, score, meta?} ]
        """
        name = collection_name or self.collection_name
        self.connect(alias)
        col = Collection(name=name, using=alias)

        # å…¼å®¹ï¼šç¡®ä¿å­˜å‚¨ç´¢å¼• metric ä¸æœç´¢ metric ä¸€è‡´ï¼ˆè‹¥ä¸ä¸€è‡´ Milvus ä¹Ÿä¼šæŒ‰ç´¢å¼•çš„ metric æ¥ï¼‰
        search_params = {"metric_type": metric_type, "params": {"nprobe": nprobe}}
        output_fields = output_fields or ["doc_id", "chunk_id", "meta"]

        if not isinstance(query_vector, np.ndarray):
            query_vector = np.asarray(query_vector, dtype="float32")
        if query_vector.dtype != np.float32:
            query_vector = query_vector.astype("float32")

        # Milvus è¦æ±‚äºŒç»´æ•°ç»„ï¼š[ [dim], [dim], ... ]
        data = [query_vector.tolist()]

        try:
            res = col.search(
                data=data,
                anns_field="vector",
                param=search_params,
                limit=top_k,
                output_fields=output_fields,
            )
        except Exception as e:
            print(f"âŒ Milvus search error: {e}")
            return [{"error": str(e)}]

        hits = []
        # res[0] æ˜¯ç¬¬ä¸€ä¸ªæŸ¥è¯¢å‘é‡çš„å‘½ä¸­åˆ—è¡¨
        for hit in res[0]:
            item = {
                "score": hit.distance,
            }
            # å‘½ä¸­å®ä½“å­—æ®µ
            try:
                # æ–°ç‰ˆ PyMilvus å»ºè®®é€šè¿‡ entity.get()
                for f in output_fields:
                    item[f] = hit.entity.get(f)
            except Exception:
                # æ—§ç‰ˆå¯èƒ½ç”¨ ._entity æˆ– .id ç­‰ï¼Œè¿™é‡Œä¿æŒå®¹é”™
                pass
            hits.append(item)

        return hits
